# ============================================================================
# BARC: Bayesian Assessment of Research Causality
# Hierarchical Bayesian Model for Pharmacovigilance Signal Assessment
# TUTORIAL VERSION - Complete working implementation
# ============================================================================

# %% [markdown]
# # BARC Tutorial: Bayesian Pharmacovigilance with PyMC
# 
# This notebook implements a hierarchical Bayesian model that integrates:
# - Randomized controlled trial data (Poisson likelihood)
# - Case reports (Negative Binomial with time-varying effects)
# - Pharmacovigilance databases (Normal with bias correction)
# - Mechanistic studies (Normal with heterogeneity)
# 
# **IMPORTANT:** This uses SIMULATED DATA for demonstration only.
# All data are patterned after the GLP-1/NAION controversy but are NOT real.

# %% [markdown]
# ## 1. Installation and Setup

# %%
# ============================================================================
# 1. INSTALLATION AND IMPORTS
# ============================================================================

# Install specific versions for reproducibility - with compatible versions
!pip install pymc==5.27.0 arviz==0.22.0 numpy==2.0.2 pytensor==2.36.0 matplotlib==3.10.0 pandas==2.2.3

import pymc as pm
import pytensor.tensor as pt
import numpy as np
import pandas as pd
import arviz as az
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Set style
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Print versions (for reproducibility checking)
print(f"PyMC version: {pm.__version__}")
print(f"ArviZ version: {az.__version__}")
print(f"NumPy version: {np.__version__}")

# Set random seed for reproducibility within this environment
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)

# %% [markdown]
# ## 2. USER CONFIGURATION SECTION
# 
# **MODIFY THIS SECTION FOR YOUR OWN DATA**
# 
# All tunable parameters are here. Replace the simulated values below
# with your actual data. Create a copy of this notebook for each analysis.

# %%
# ============================================================================
# 2. USER CONFIGURATION - MODIFY THESE VALUES FOR YOUR DATA
# ============================================================================

# ----------------------------------------------------------------------------
# 2.1 RCT Data (replace with your values)
# ----------------------------------------------------------------------------
# Format: events (integer) and person-years (float/integer)
GLP1_EVENTS = 8        # Events in GLP-1 exposed group
GLP1_PY = 144226        # Person-years of exposure
COMP_EVENTS = 4         # Events in comparator/unexposed group
COMP_PY = 132922        # Person-years in comparator

# ----------------------------------------------------------------------------
# 2.2 Case Reports - Time Series (replace with your monthly counts)
# ----------------------------------------------------------------------------
# Full time series of monthly case counts (60 months in this example)
# Replace with your actual monthly counts from FAERS, EudraVigilance, etc.
CASE_COUNTS = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
               0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1,
               0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

# Number of months (will be inferred from data length)
N_MONTHS = len(CASE_COUNTS)

# ----------------------------------------------------------------------------
# 2.3 Pharmacovigilance Data (replace with your values)
# ----------------------------------------------------------------------------
ROR_OBSERVED = 1.23     # Reporting Odds Ratio from disproportionality analysis
ROR_SE = 0.35           # Standard error of log(ROR)

# ----------------------------------------------------------------------------
# 2.4 Mechanistic Studies (replace with your effect sizes)
# ----------------------------------------------------------------------------
# Effect sizes from individual mechanistic studies (e.g., fold changes, standardized mean differences)
MECH_EFFECTS = [0.3, 0.5, -0.1, 0.2, 0.7, 0.1, 0.4, 0.0, 0.6, 0.3]

# ----------------------------------------------------------------------------
# 2.5 PRIOR PARAMETERS (adjust based on your context)
# ----------------------------------------------------------------------------
# Prior probability of causation: Beta(alpha, beta)
# Beta(10,190) gives mean 5%, 95% interval [2.4%, 8.2%]
P_H_ALPHA = 10
P_H_BETA = 190

# Baseline NAION rate prior: Gamma(alpha, beta)
# Gamma(4,1.5) gives mean ~2.7 per 100k PY, 95% CI [0.8, 5.8]
BASELINE_RATE_ALPHA = 4
BASELINE_RATE_BETA = 1.5

# ----------------------------------------------------------------------------
# 2.6 CALIBRATION MULTIPLIERS (adjust based on your context)
# ----------------------------------------------------------------------------
# These link the latent pathway θ to each evidence stream
# With current values, θ=1 corresponds to:
# - RCT: 65% increase in IRR
# - Case reports: 35% increase in reporting rate
# - PV: moderate signal (0.4 on log scale)
# - Mechanistic: moderate-large effect (0.6)

MULTIPLIER_RCT = 0.5
MULTIPLIER_CASE = 0.3
MULTIPLIER_PV = 0.4
MULTIPLIER_MECH = 0.6
THETA_SCALING = 0.4      # Scales prior probability to theta
THETA_SD = 0.5           # Uncertainty in theta

# ----------------------------------------------------------------------------
# 2.7 SAMPLING PARAMETERS (adjust for your analysis)
# ----------------------------------------------------------------------------
N_DRAWS = 1000           # Posterior samples per chain (increase to 4000+ for final)
N_TUNE = 1000            # Tuning iterations (increase to 2000+ for complex models)
N_CHAINS = 4             # Number of MCMC chains
TARGET_ACCEPT = 0.95     # Target acceptance rate (higher for hierarchical models)

# ============================================================================
# END USER CONFIGURATION
# ============================================================================

# %% [markdown]
# ## 3. Basic Data Validation
# 
# Simple checks to catch common errors.

# %%
# ============================================================================
# 3. BASIC DATA VALIDATION
# ============================================================================

print("\n" + "="*80)
print("3. VALIDATING INPUT DATA")
print("="*80)

validation_errors = []

# RCT data validation
if not isinstance(GLP1_EVENTS, (int, np.integer)):
    validation_errors.append("GLP1_EVENTS must be an integer")
if GLP1_PY <= 0:
    validation_errors.append("GLP1_PY must be positive")
if not isinstance(COMP_EVENTS, (int, np.integer)):
    validation_errors.append("COMP_EVENTS must be an integer")
if COMP_PY <= 0:
    validation_errors.append("COMP_PY must be positive")

# Case reports validation
CASE_COUNTS = np.asarray(CASE_COUNTS)
if CASE_COUNTS.ndim != 1:
    validation_errors.append("CASE_COUNTS must be 1-dimensional")
if np.any(CASE_COUNTS < 0):
    validation_errors.append("CASE_COUNTS cannot contain negative values")
if not np.all(CASE_COUNTS == CASE_COUNTS.astype(int)):
    validation_errors.append("CASE_COUNTS must contain integers")

# PV data validation
if ROR_OBSERVED <= 0:
    validation_errors.append("ROR_OBSERVED must be positive")
if ROR_SE <= 0:
    validation_errors.append("ROR_SE must be positive")

# Mechanistic data validation
MECH_EFFECTS = np.asarray(MECH_EFFECTS)
if len(MECH_EFFECTS) == 0:
    validation_errors.append("MECH_EFFECTS cannot be empty")

# Report validation results
if validation_errors:
    print("\n❌ VALIDATION ERRORS FOUND:")
    for error in validation_errors:
        print(f"  • {error}")
    print("\nPlease fix these errors before proceeding.")
    # Stop execution if in script mode
    # raise ValueError("Data validation failed")
else:
    print("\n✓ All basic validation checks passed")

print(f"\nData summary:")
print(f"  RCT: {GLP1_EVENTS}/{COMP_EVENTS} events, {GLP1_PY:.0f}/{COMP_PY:.0f} PY")
print(f"  Case reports: {N_MONTHS} months, mean {CASE_COUNTS.mean():.2f}/month")
print(f"  PV: ROR={ROR_OBSERVED}, SE={ROR_SE}")
print(f"  Mechanistic: {len(MECH_EFFECTS)} studies, mean {MECH_EFFECTS.mean():.2f}")

# %% [markdown]
# ## 4. Model Specification

# %%
# ============================================================================
# 4. HIERARCHICAL BAYESIAN MODEL
# ============================================================================

print("\n" + "="*80)
print("4. BUILDING HIERARCHICAL BAYESIAN MODEL")
print("="*80)

with pm.Model() as barc_model:
    
    # ------------------------------------------------------------------------
    # 4.1 PRIORS
    # ------------------------------------------------------------------------
    print("\n4.1 Specifying priors...")
    
    # Prior probability of causation (conservative "presume safe" stance)
    p_H_prior = pm.Beta("p_H_prior", alpha=P_H_ALPHA, beta=P_H_BETA)
    
    # Latent pathway parameter - NON-CENTERED for better sampling
    # theta > 0: harmful pathway, theta ≈ 0: no effect, theta < 0: protective
    theta_mu = p_H_prior * THETA_SCALING
    theta_offset = pm.Normal("theta_offset", mu=0, sigma=1)
    theta = pm.Deterministic("theta", theta_mu + theta_offset * THETA_SD)
    
    # ------------------------------------------------------------------------
    # 4.2 RCT EVIDENCE STREAM
    # ------------------------------------------------------------------------
    print("4.2 Adding RCT stream...")
    
    # Baseline NAION incidence (per 100,000 person-years)
    baseline_rate = pm.Gamma("baseline_rate", 
                             alpha=BASELINE_RATE_ALPHA, 
                             beta=BASELINE_RATE_BETA)
    
    # GLP-1 exposed rate: baseline modified by pathway effect
    rate_GLP1 = pm.Deterministic(
        "rate_GLP1",
        baseline_rate * pt.exp(theta * MULTIPLIER_RCT)
    )
    
    # Comparator rate (unexposed)
    rate_comp = pm.Deterministic("rate_comp", baseline_rate)
    
    # Expected event counts (convert rates to counts using exposure)
    expected_GLP1 = rate_GLP1 * (GLP1_PY / 100000)
    expected_comp = rate_comp * (COMP_PY / 100000)
    
    # Poisson likelihood for rare events
    obs_GLP1 = pm.Poisson("obs_GLP1", 
                          mu=expected_GLP1,
                          observed=GLP1_EVENTS)
    obs_comp = pm.Poisson("obs_comp", 
                          mu=expected_comp,
                          observed=COMP_EVENTS)
    
    # Derived: Incidence Rate Ratio
    IRR = pm.Deterministic("IRR", rate_GLP1 / rate_comp)
    
    # ------------------------------------------------------------------------
    # 4.3 CASE REPORT STREAM (Full time series with temporal effects)
    # ------------------------------------------------------------------------
    print("4.3 Adding case report stream...")
    
    # Dispersion parameter for Negative Binomial
    alpha_nb = pm.Exponential("alpha_nb", lam=2)
    
    # Time-varying effect - Gaussian random walk
    # Captures changing reporting rates over time (awareness, media coverage)
    time_effect_raw = pm.Normal("time_effect_raw", mu=0, sigma=0.1, shape=N_MONTHS)
    time_effect = pm.Deterministic("time_effect", time_effect_raw.cumsum())
    
    # Mean monthly cases: baseline + pathway effect + time trend
    # Baseline 0.15 cases/month from pre-signal reporting rates
    log_mu_base = pt.log(0.15) + theta * MULTIPLIER_CASE
    log_mu_t = log_mu_base + time_effect * 0.05  # Time component
    mu_cases = pm.Deterministic("mu_cases", pt.exp(log_mu_t))
    
    # Negative Binomial likelihood using FULL TIME SERIES
    obs_cases = pm.NegativeBinomial(
        "obs_cases",
        mu=mu_cases,
        alpha=alpha_nb,
        observed=CASE_COUNTS
    )
    
    # ------------------------------------------------------------------------
    # 4.4 PHARMACOVIGILANCE STREAM (with bias correction)
    # ------------------------------------------------------------------------
    print("4.4 Adding pharmacovigilance stream...")
    
    # True log Reporting Odds Ratio (linked to pathway)
    logROR_true = pm.Normal("logROR_true", 
                            mu=theta * MULTIPLIER_PV, 
                            sigma=0.4)
    
    # Reporting bias: spontaneous systems tend to over-report new signals
    reporting_bias = pm.Normal("reporting_bias", mu=0.12, sigma=0.06)
    
    # Measurement model: observed = true + bias + error
    obs_logROR = pm.Normal(
        "obs_logROR",
        mu=logROR_true + reporting_bias,
        sigma=ROR_SE,
        observed=np.log(ROR_OBSERVED)
    )
    
    # ROR on natural scale for interpretation
    ROR = pm.Deterministic("ROR", pt.exp(logROR_true))
    
    # ------------------------------------------------------------------------
    # 4.5 MECHANISTIC STUDIES STREAM (hierarchical meta-analysis)
    # ------------------------------------------------------------------------
    print("4.5 Adding mechanistic stream...")
    
    # True mechanistic effect (linked to pathway)
    mech_true = pm.Normal("mech_true", 
                          mu=theta * MULTIPLIER_MECH, 
                          sigma=0.3)
    
    # Between-study heterogeneity
    mech_sigma = pm.HalfNormal("mech_sigma", sigma=0.35)
    
    # Likelihood for individual study estimates
    obs_mech = pm.Normal(
        "obs_mech",
        mu=mech_true,
        sigma=mech_sigma,
        observed=MECH_EFFECTS
    )
    
    # ------------------------------------------------------------------------
    # 4.6 DECISION-RELEVANT DERIVED QUANTITIES
    # ------------------------------------------------------------------------
    print("4.6 Computing derived quantities...")
    
    # Excess absolute risk (additional cases per 100,000 PY)
    excess_rate = pm.Deterministic("excess_rate", rate_GLP1 - rate_comp)
    
    # Number Needed to Harm (with protection against division by zero)
    # Floor at 0.03 prevents NNH > 3.3 million from numerical issues
    safe_excess = pm.math.maximum(excess_rate, 0.03)
    NNH = pm.Deterministic("NNH", 100000 / safe_excess)
    
    print("\n✓ Model specification complete")

# %% [markdown]
# ## 5. MCMC Sampling

# %%
# ============================================================================
# 5. MCMC SAMPLING
# ============================================================================

print("\n" + "="*80)
print("5. MCMC SAMPLING")
print("="*80)
print(f"\nSampling parameters:")
print(f"  • Draws: {N_DRAWS} per chain")
print(f"  • Tune: {N_TUNE}")
print(f"  • Chains: {N_CHAINS}")
print(f"  • Target accept: {TARGET_ACCEPT}")

with barc_model:
    trace = pm.sample(
        draws=N_DRAWS,
        tune=N_TUNE,
        chains=N_CHAINS,
        cores=2,
        random_seed=RANDOM_SEED,
        target_accept=TARGET_ACCEPT,
        return_inferencedata=True,
        idata_kwargs={'log_likelihood': True},
        progressbar=True
    )

print("\n✓ Sampling completed")

# %% [markdown]
# ## 6. Convergence Diagnostics
# 
# **Always check these before interpreting results.**

# %%
# ============================================================================
# 6. CONVERGENCE DIAGNOSTICS
# ============================================================================

print("\n" + "="*80)
print("6. CONVERGENCE DIAGNOSTICS")
print("="*80)

# 6.1 R-hat values
print("\n6.1 R-hat values (should be < 1.01):")
summary = az.summary(trace, var_names=['p_H_prior', 'theta', 'IRR', 'excess_rate', 'NNH'])

# Display available columns
print("\nAvailable columns:", summary.columns.tolist())

# Get HDI columns (varies by ArviZ version)
hdi_cols = [col for col in summary.columns if 'hdi' in col]
if len(hdi_cols) >= 2:
    display_cols = ['mean', 'sd'] + hdi_cols[:2] + ['r_hat']
else:
    display_cols = ['mean', 'sd', 'r_hat']

display_cols = [col for col in display_cols if col in summary.columns]
print("\nSummary Statistics:")
print(summary[display_cols].round(3))

# Check max R-hat
max_rhat = summary['r_hat'].max()
print(f"\nMaximum R-hat: {max_rhat:.3f}")
if max_rhat < 1.01:
    print("✓ All R-hat < 1.01: Good convergence")
elif max_rhat < 1.05:
    print("⚠ Some R-hat > 1.01 but < 1.05: May need longer sampling")
else:
    print("❌ R-hat > 1.05: Poor convergence - increase tuning/draws")

# 6.2 Divergences
if hasattr(trace, 'sample_stats') and 'divergences' in trace.sample_stats:
    divergences = trace.sample_stats['divergences'].values.sum()
    print(f"\nDivergences: {divergences}")
    if divergences == 0:
        print("✓ No divergences")
    else:
        print(f"⚠ {divergences} divergences - consider reparameterization")

# 6.3 Effective Sample Size
if 'ess_bulk' in summary.columns:
    min_ess = summary['ess_bulk'].min()
    print(f"\nMinimum bulk ESS: {min_ess:.0f}")
    if min_ess > 400:
        print("✓ ESS > 400: Sufficient samples")
    elif min_ess > 200:
        print("⚠ ESS 200-400: May be adequate")
    else:
        print("❌ ESS < 200: Increase draws")

# 6.4 Trace plots (compact)
print("\n6.4 Generating trace plots...")
for var in ['p_H_prior', 'theta', 'IRR']:
    fig = plt.figure(figsize=(10, 3))
    az.plot_trace(trace, var_names=[var], compact=True)
    plt.suptitle(f'{var} - Trace Plot')
    plt.tight_layout()
    plt.show()

# %% [markdown]
# ## 7. Posterior Predictive Checks
# 
# Does the model generate data consistent with observations?

# %%
# ============================================================================
# 7. POSTERIOR PREDICTIVE CHECKS
# ============================================================================

print("\n" + "="*80)
print("7. POSTERIOR PREDICTIVE CHECKS")
print("="*80)

with barc_model:
    ppc = pm.sample_posterior_predictive(trace, random_seed=RANDOM_SEED)

fig, axes = plt.subplots(1, 2, figsize=(12, 4))
az.plot_ppc(ppc, var_names=['obs_GLP1'], ax=axes[0], num_pp_samples=100)
axes[0].set_title('Posterior Predictive: GLP-1 Events')
az.plot_ppc(ppc, var_names=['obs_comp'], ax=axes[1], num_pp_samples=100)
axes[1].set_title('Posterior Predictive: Comparator Events')
plt.tight_layout()
plt.show()

# %% [markdown]
# ## 8. Posterior Results and Interpretation

# %%
# ============================================================================
# 8. POSTERIOR RESULTS
# ============================================================================

print("\n" + "="*80)
print("8. POSTERIOR RESULTS")
print("="*80)

# Extract posterior samples
posterior = trace.posterior

# 8.1 Bayesian updating
print("\n8.1 Bayesian belief updating:")

# Prior samples
prior_samples = posterior['p_H_prior'].values.flatten()

# Compute P(theta > 0) directly from samples
theta_samples = posterior['theta'].values.flatten()
p_theta_positive = np.mean(theta_samples > 0)

# Posterior probability of causation = prior * I(theta > 0)
posterior_causal = prior_samples * (theta_samples > 0)

prior_mean = np.mean(prior_samples)
prior_ci = np.percentile(prior_samples, [2.5, 97.5])
post_mean = np.mean(posterior_causal)
post_ci = np.percentile(posterior_causal, [2.5, 97.5])
update_factor = post_mean / prior_mean

print(f"  Prior P(H): {prior_mean:.1%} [{prior_ci[0]:.1%}, {prior_ci[1]:.1%}]")
print(f"  P(theta > 0 | data): {p_theta_positive:.1%}")
print(f"  Posterior P(H|E): {post_mean:.1%} [{post_ci[0]:.1%}, {post_ci[1]:.1%}]")
print(f"  Update factor: {update_factor:.2f}x")

# Visualize
fig, ax = plt.subplots(figsize=(10, 4))
az.plot_dist(prior_samples, label='Prior P(H)', color='C0', ax=ax)
az.plot_dist(posterior_causal, label='Posterior P(H|E)', color='C1', ax=ax)
ax.axvline(prior_mean, color='C0', linestyle='--', alpha=0.5)
ax.axvline(post_mean, color='C1', linestyle='--', alpha=0.5)
ax.set_xlabel('Probability')
ax.set_ylabel('Density')
ax.set_title('Prior vs Posterior Probability of Causation')
ax.legend()
plt.show()

# 8.2 Effect estimates
print("\n8.2 Effect estimates:")

# IRR
IRR_samples = posterior['IRR'].values.flatten()
IRR_mean = np.mean(IRR_samples)
IRR_ci = np.percentile(IRR_samples, [2.5, 97.5])
IRR_p_gt1 = np.mean(IRR_samples > 1)
print(f"  IRR: {IRR_mean:.2f} [{IRR_ci[0]:.2f}, {IRR_ci[1]:.2f}]")
print(f"  P(IRR > 1): {IRR_p_gt1:.1%}")

# ROR
if 'ROR' in posterior:
    ROR_samples = posterior['ROR'].values.flatten()
    ROR_mean = np.mean(ROR_samples)
    ROR_ci = np.percentile(ROR_samples, [2.5, 97.5])
    ROR_p_gt1 = np.mean(ROR_samples > 1)
    print(f"  ROR: {ROR_mean:.2f} [{ROR_ci[0]:.2f}, {ROR_ci[1]:.2f}]")
    print(f"  P(ROR > 1): {ROR_p_gt1:.1%}")

# Theta
theta_mean = np.mean(theta_samples)
theta_ci = np.percentile(theta_samples, [2.5, 97.5])
print(f"  θ: {theta_mean:.3f} [{theta_ci[0]:.3f}, {theta_ci[1]:.3f}]")
print(f"  P(θ > 0): {p_theta_positive:.1%}")

# 8.3 Harm quantification
print("\n8.3 Harm quantification:")

# Baseline rate
baseline_samples = posterior['baseline_rate'].values.flatten()
baseline_mean = np.mean(baseline_samples)
baseline_ci = np.percentile(baseline_samples, [2.5, 97.5])
print(f"  Baseline NAION rate: {baseline_mean:.1f} [{baseline_ci[0]:.1f}, {baseline_ci[1]:.1f}] per 100k PY")

# Excess rate (report both mean and median due to skewness)
excess_samples = posterior['excess_rate'].values.flatten()
excess_mean = np.mean(excess_samples)
excess_median = np.median(excess_samples)
excess_ci = np.percentile(excess_samples, [2.5, 97.5])
excess_p_gt0 = np.mean(excess_samples > 0)
excess_p_gt1 = np.mean(excess_samples > 1)

print(f"  Excess rate (mean): {excess_mean:.2f} per 100k PY")
print(f"  Excess rate (median): {excess_median:.2f} per 100k PY")
print(f"  95% CI: [{excess_ci[0]:.2f}, {excess_ci[1]:.2f}] per 100k PY")
print(f"  P(excess > 0): {excess_p_gt0:.1%}")
print(f"  P(excess > 1/100k): {excess_p_gt1:.1%}")

# Check skewness
if excess_mean > excess_median * 1.5:
    print("  ⚠ Note: Excess rate distribution is right-skewed (mean > median)")
    print("    The median may be more interpretable than the mean.")

# NNH
NNH_samples = posterior['NNH'].values.flatten()
NNH_mean = np.mean(NNH_samples)
NNH_median = np.median(NNH_samples)
NNH_ci = np.percentile(NNH_samples, [2.5, 97.5])

print(f"\n  NNH (mean): {NNH_mean/1000:.0f}k patient-years")
print(f"  NNH (median): {NNH_median/1000:.0f}k patient-years")
print(f"  95% CI: [{NNH_ci[0]/1000:.0f}k, {NNH_ci[1]/1000:.0f}k] patient-years")

if NNH_mean > NNH_median * 2:
    print("  ⚠ Note: NNH distribution is extremely right-skewed")
    print("    The median is more interpretable than the mean")

# Visualize harm metrics
fig, axes = plt.subplots(1, 3, figsize=(15, 4))

az.plot_posterior(trace, var_names=['excess_rate'], ref_val=0, ax=axes[0])
axes[0].axvline(1, color='red', linestyle='--', alpha=0.5, label='Threshold (1)')
axes[0].set_title('Excess Risk (per 100k PY)')
axes[0].legend()

az.plot_posterior(trace, var_names=['NNH'], ax=axes[1])
axes[1].set_xscale('log')
axes[1].set_title('NNH (log scale)')

# Threshold probability curve
thresholds = np.linspace(0, 3, 50)
threshold_probs = [np.mean(excess_samples > t) for t in thresholds]
axes[2].plot(thresholds, threshold_probs)
axes[2].axhline(0.5, color='gray', linestyle='--', alpha=0.5)
axes[2].axvline(1, color='red', linestyle='--', alpha=0.5)
axes[2].set_xlabel('Excess Risk Threshold (per 100k PY)')
axes[2].set_ylabel('P(excess > threshold)')
axes[2].set_title('Threshold Probability Curve')
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# 8.4 Summary table
print("\n8.4 Results summary:")
results_summary = pd.DataFrame({
    'Parameter': [
        'Prior P(H)',
        'P(theta > 0 | data)',
        'Posterior P(H|E)',
        'IRR',
        'P(IRR > 1)',
        'Baseline Rate (per 100k PY)',
        'Excess Rate - Mean (per 100k PY)',
        'Excess Rate - Median (per 100k PY)',
        'P(excess > 1/100k)',
        'NNH Median (k PY) [95% CI]'
    ],
    'Estimate': [
        f"{prior_mean:.1%} [{prior_ci[0]:.1%}, {prior_ci[1]:.1%}]",
        f"{p_theta_positive:.1%}",
        f"{post_mean:.1%} [{post_ci[0]:.1%}, {post_ci[1]:.1%}]",
        f"{IRR_mean:.2f} [{IRR_ci[0]:.2f}, {IRR_ci[1]:.2f}]",
        f"{IRR_p_gt1:.1%}",
        f"{baseline_mean:.1f} [{baseline_ci[0]:.1f}, {baseline_ci[1]:.1f}]",
        f"{excess_mean:.2f} [{excess_ci[0]:.2f}, {excess_ci[1]:.2f}]",
        f"{excess_median:.2f}",
        f"{excess_p_gt1:.1%}",
        f"{NNH_median/1000:.0f} [{NNH_ci[0]/1000:.0f}, {NNH_ci[1]/1000:.0f}]"
    ]
})

print(results_summary.to_string(index=False))

# %% [markdown]
# ## 9. Plain Language Interpretation
# 
# **IMPORTANT: These interpretations apply to the SIMULATED DATA only.**
# They demonstrate how to communicate results, not actual findings about GLP-1/NAION.

# %%
# ============================================================================
# 9. PLAIN LANGUAGE INTERPRETATION (Demonstration Only)
# ============================================================================

print("\n" + "="*80)
print("9. PLAIN LANGUAGE INTERPRETATION")
print("="*80)
print(f"""
WHAT THIS ANALYSIS SHOWS (FOR SIMULATED DATA ONLY):

1. Bayesian Learning:
   • Started with conservative assumption: 5% probability GLP-1 causes NAION
   • After evidence: {p_theta_positive:.1%} chance biological pathway is active
   • Overall probability of causation: {post_mean:.1%}
   • Evidence {'increased' if update_factor > 1 else 'decreased'} belief (update factor: {update_factor:.2f}x)

2. Effect Size:
   • Most likely relative risk increase: {IRR_mean:.2f}-fold
   • {IRR_p_gt1:.1%} chance of any increase (IRR > 1)
   • But wide CI [{IRR_ci[0]:.2f}, {IRR_ci[1]:.2f}] includes no effect

3. What This Means for Patients:
   • Background NAION risk: {baseline_mean:.1f} per 100,000 people per year
   • Additional risk with GLP-1: median {excess_median:.2f} extra cases per 100,000
   • Number needed to harm: {NNH_median/1000:.0f},000 patient-years

4. Key Uncertainty:
   • {excess_p_gt1:.1%} chance excess risk exceeds 1 per 100,000
   • Data don't definitively resolve clinical meaningfulness

5. IMPORTANT DISCLAIMER:
   These are SIMULATED DATA results. They demonstrate the method only.
   No conclusions about actual GLP-1/NAION safety should be drawn.
""")

# %% [markdown]
# ## 10. Export Results (Optional)

# %%
# ============================================================================
# 10. EXPORT RESULTS (Optional - modify paths as needed)
# ============================================================================

print("\n" + "="*80)
print("10. EXPORTING RESULTS")
print("="*80)

# Save summary table
results_summary.to_csv('barc_results_demo.csv', index=False)
print("✓ Results saved to 'barc_results_demo.csv'")

# Save trace for later analysis
az.to_netcdf(trace, 'barc_trace_demo.nc')
print("✓ Trace saved to 'barc_trace_demo.nc'")

# %% [markdown]
# ## 11. Session Info

# %%
# ============================================================================
# 11. SESSION INFORMATION
# ============================================================================

print("\n" + "="*80)
print("11. SESSION INFORMATION")
print("="*80)

import sys
print(f"Python: {sys.version}")
print(f"PyMC: {pm.__version__}")
print(f"ArviZ: {az.__version__}")
print(f"NumPy: {np.__version__}")
print(f"Random seed: {RANDOM_SEED}")

print("\n" + "="*80)
print("TUTORIAL COMPLETE")
print("="*80)
print("""
NEXT STEPS FOR YOUR OWN DATA:
1. Create a copy of this notebook
2. Replace values in USER CONFIGURATION section (Section 2)
3. Adjust priors and multipliers for your context
4. Run and check convergence
5. Interpret results

For production use, consider adding:
- More extensive input validation
- Error handling
- Unit tests
- Configuration files
""")
